{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reviewer Introduction\n",
        "\n",
        "Hello STUDENT NAME!\n",
        "\n",
        "Hello, my name is Juan Miguel Gutierrez, also known as Juanmi ! \n",
        "\n",
        "I'm delighted to assist you with your project today.As part of my role, I will review your work and provide feedback. Initially, if I notice any mistakes, I will simply point them out, allowing you to identify and correct them on your own. This approach is aimed at helping you develop the skills required for a career as a Data Scientist.\n",
        "\n",
        "In a real job setting, it's common for a team lead or supervisor to follow a similar approach, encouraging you to troubleshoot and find solutions independently. However, if you find the task challenging and need further guidance, I will offer more precise hints and suggestions in subsequent iterations.\n",
        "\n",
        "Please feel free to ask for assistance or clarification whenever needed. I'm here to support you in your journey towards becoming a skilled Data Scientist.\n",
        "\n",
        "You will find my comments below - please do not move, modify or delete them.\n",
        "You can find my comments in green, yellow or red boxes like this:\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "Success. Everything is done succesfully.\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "Remarks. Some recommendations.\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "Needs fixing. The block requires some corrections. Work can't be accepted with the red comments.\n",
        "</div>\n",
        "\n",
        "You can answer me by using this:\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Student answer.</b> <a class=\"tocSkip\"></a>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### General feedback V1\n",
        "\n",
        "\n",
        "The analysis for the project was excellent, and I thoroughly enjoyed reading the entire project. There were several aspects that stood out to me:\n",
        "\n",
        "* The project demonstrated a solid understanding of the hyperparameters used in the decision tree model.\n",
        "* The data was correctly split and a sanity check was performed on the shape, ensuring the data was handled appropriately.\n",
        "* The quality check of the data was thorough and well-executed, resulting in clean and reliable data.\n",
        "* The code itself was clean and well-organized, making it easy to follow and understand.\n",
        "\n",
        "However, there are a few issues that need to be addressed in order to conclude the project. These issues are marked in the code with a \"Danger\" tag, and I would recommend focusing on resolving them:\n",
        "\n",
        "* It seems that the data split may be unbalanced, which could affect the model's performance. Please refer to [Warning 1](#warning1) and [Warning 0](#warning0) in the code for more details.\n",
        "* There was not a sufficient iteration of parameters for the model. It is recommended to try at least three different parameter combinations to find the optimal configuration. Please refer to [Danger 1](#danger1) in the code for more information.\n",
        "* The accuracy of the train set and other important sanity checks were not displayed. It would be beneficial to include these metrics for a comprehensive evaluation. Please see [Warning 2](#warning2) in the code for further guidance.\n",
        "\n",
        "* A proper sanity check of the model, such as comparing it with baselines or using a confusion matrix, was not performed. This step is crucial in assessing the model's performance. Please refer to [Warning 3](#warning3) in the code for suggestions on how to address this.\n",
        "\n",
        "In general, with these fixes, the project will be fantastic and well-rounded. I appreciate the ordered code, excellent explanations, and your proficiency in Python. Don't forget to implement the necessary fixes and update the conclusions accordingly.\n",
        "\n",
        "If you have any further questions or need assistance, feel free to ask. Good luck with the project!\n",
        "\n",
        "\n",
        "**Review Checklist**\n",
        "\n",
        "- [x] Data is loaded\n",
        "- [x] Data is split into three sets\n",
        "- [x] Sets' sizes are chosen correctly\n",
        "- [x] Models tuning is conducted \n",
        "- [x] Tuning is conducted correctly\n",
        "- [ ] At least 2 algorithms and at least 3 values of hyperparameters are considered\n",
        "- [x] Study findings are complete \n",
        "- [x] Model testing is complete\n",
        "- [x] Testing is done correctly \n",
        "- [x] Accuracy is at least 0.75"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5jbpaOmr1z3r"
      },
      "source": [
        "# Project description\n",
        "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
        "\n",
        "You have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course). For this classification task, you need to develop a model that will pick the right plan. Since youâ€™ve already performed the data preprocessing step, you can move straight to creating the model.\n",
        "\n",
        "Develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "475JeDOm1z3r"
      },
      "source": [
        "I will finish the project using the following steps:\n",
        "    \n",
        "- Open and look through the data file. Path to the file: /datasets/users_behavior.csv .\n",
        "\n",
        "- Spliting the source data into a training set, a validation set, and a test set.\n",
        "\n",
        "- Investigate the quality of different models by changing hyperparameters. While Briefly describing the findings of the study.\n",
        "\n",
        "- Checking the quality of the model using the test set.\n",
        "\n",
        "- Additional task: sanity check the model. This data is more complex than what I am used to working with, so it's not an easy task. We'll take a closer look at it later."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_vEqoFAk1z3s",
        "toc": true
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Review-Iterations-1\" data-toc-modified-id=\"Review-Iterations-1-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Review Iterations 1</a></span></li><li><span><a href=\"#Importing-files\" data-toc-modified-id=\"Importing-files-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Importing files</a></span></li><li><span><a href=\"#Spliting-the-source-data-into-a-training-set,-a-validation-set,-and-a-test-set.\" data-toc-modified-id=\"Spliting-the-source-data-into-a-training-set,-a-validation-set,-and-a-test-set.-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Spliting the source data into a training set, a validation set, and a test set.</a></span></li><li><span><a href=\"#Investigate-the-quality-of-different-models-by-changing-hyperparameters.-While-Briefly-describing-the-findings-of-the-study.\" data-toc-modified-id=\"Investigate-the-quality-of-different-models-by-changing-hyperparameters.-While-Briefly-describing-the-findings-of-the-study.-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Investigate the quality of different models by changing hyperparameters. While Briefly describing the findings of the study.</a></span></li><li><span><a href=\"#Checking-the-quality-of-the-model-using-the-test-set.\" data-toc-modified-id=\"Checking-the-quality-of-the-model-using-the-test-set.-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Checking the quality of the model using the test set.</a></span></li><li><span><a href=\"#Additional-task:-sanity-check-the-model.\" data-toc-modified-id=\"Additional-task:-sanity-check-the-model.-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Additional task: sanity check the model.</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "na_d2sEl1z3t"
      },
      "source": [
        "## Importing files\n",
        "Importing files and checking data for any incorrect data types, missing values or duplicate values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9yBD5noq1z3t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ss2LKt3g1z3u"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"https://code.s3.yandex.net/datasets/users_behavior.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XtQustZl1z3v",
        "outputId": "0c8b7d22-50d4-4cfd-eb2f-d5f4a97b6b76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>calls</th>\n",
              "      <th>minutes</th>\n",
              "      <th>messages</th>\n",
              "      <th>mb_used</th>\n",
              "      <th>is_ultra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.0</td>\n",
              "      <td>311.90</td>\n",
              "      <td>83.0</td>\n",
              "      <td>19915.42</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85.0</td>\n",
              "      <td>516.75</td>\n",
              "      <td>56.0</td>\n",
              "      <td>22696.96</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>77.0</td>\n",
              "      <td>467.66</td>\n",
              "      <td>86.0</td>\n",
              "      <td>21060.45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106.0</td>\n",
              "      <td>745.53</td>\n",
              "      <td>81.0</td>\n",
              "      <td>8437.39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66.0</td>\n",
              "      <td>418.74</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14502.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   calls  minutes  messages   mb_used  is_ultra\n",
              "0   40.0   311.90      83.0  19915.42         0\n",
              "1   85.0   516.75      56.0  22696.96         0\n",
              "2   77.0   467.66      86.0  21060.45         0\n",
              "3  106.0   745.53      81.0   8437.39         1\n",
              "4   66.0   418.74       1.0  14502.75         0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "FBqfHjcL1z3v",
        "outputId": "852eed93-6bbf-4b01-e4f3-c0a3f0f050fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3214 entries, 0 to 3213\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   calls     3214 non-null   float64\n",
            " 1   minutes   3214 non-null   float64\n",
            " 2   messages  3214 non-null   float64\n",
            " 3   mb_used   3214 non-null   float64\n",
            " 4   is_ultra  3214 non-null   int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 125.7 KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPecufA91z3w",
        "outputId": "74d1aa4b-6481-4a40-b51c-64d412b3ef7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "print(data[\"is_ultra\"].unique())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c9AGgNH_1z3w"
      },
      "source": [
        "All data types seems correct, with the only column that might cause problems being is_ultra. is _ultra is acting as bolean values where 0 is False and 1 is True. This might not cause problems for the model that will be developed, but if any do happen to pop up. This might be one of the possible issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "I7QROuRF1z3w",
        "outputId": "a44680d1-135c-40de-b5f5-f93158b49d52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>calls</th>\n",
              "      <th>minutes</th>\n",
              "      <th>messages</th>\n",
              "      <th>mb_used</th>\n",
              "      <th>is_ultra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3214.000000</td>\n",
              "      <td>3214.000000</td>\n",
              "      <td>3214.000000</td>\n",
              "      <td>3214.000000</td>\n",
              "      <td>3214.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>63.038892</td>\n",
              "      <td>438.208787</td>\n",
              "      <td>38.281269</td>\n",
              "      <td>17207.673836</td>\n",
              "      <td>0.306472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>33.236368</td>\n",
              "      <td>234.569872</td>\n",
              "      <td>36.148326</td>\n",
              "      <td>7570.968246</td>\n",
              "      <td>0.461100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>274.575000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>12491.902500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>62.000000</td>\n",
              "      <td>430.600000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>16943.235000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>82.000000</td>\n",
              "      <td>571.927500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>21424.700000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>244.000000</td>\n",
              "      <td>1632.060000</td>\n",
              "      <td>224.000000</td>\n",
              "      <td>49745.730000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             calls      minutes     messages       mb_used     is_ultra\n",
              "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
              "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
              "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
              "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
              "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
              "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
              "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
              "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(data.describe())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='warning0'></a>\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "I found very valuable this table. You can see that it may be a possible unbalance of ultra and smart plans. There are 30% of ultra values while 70% in smart. This can affect the accuracy intra group of your future model.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxbDo0u91z3w",
        "outputId": "2bdc2fa2-4702-4bed-aa16-bb97d97aaefe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calls       0\n",
            "minutes     0\n",
            "messages    0\n",
            "mb_used     0\n",
            "is_ultra    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpVj1TZ61z3x",
        "outputId": "eb99925f-faa0-4803-80d4-9bedb8e8e02c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "print(data.duplicated().sum())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "You did the standard approach which is cool. Remember duplicates and null values are not the only enemy of data quality. For this case everything seems ok, but remember always double check data makes sense, with some random specific cases. See row by row, sometimes you may find data does not make sense and can lead you to filter more data.\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T62_nWMN1z3x"
      },
      "source": [
        "There seems to be no missing values or duplicate rows in the dataset, and would be safe to say that we can continue."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_prfbDQe1z3x"
      },
      "source": [
        "##  Spliting the source data into a training set, a validation set, and a test set.\n",
        "Splitting the source data into a training set, a validation set and a test set for the model that will be selected. \n",
        "\n",
        "I will split the data in the following order, putting 50% of the data in the training set, 25% in the validation set, and 25% in the test set. It is default to use the largest portion of data to train the model, so it can be as accurate as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6setYdTK1z3x"
      },
      "outputs": [],
      "source": [
        "data_train, data_valid = train_test_split(data, test_size=0.5, random_state=12345)\n",
        "data_valid, data_test = train_test_split(data_valid, test_size=0.5, random_state=12345)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB6bUbPM1z3y",
        "outputId": "65575ef3-8424-4ebb-ffc1-a6a8494375cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1607, 4)\n",
            "(1607,)\n",
            "(803, 4)\n",
            "(803,)\n",
            "(804, 4)\n",
            "(804,)\n"
          ]
        }
      ],
      "source": [
        "features_train = data_train.drop([\"is_ultra\"], axis=1)\n",
        "target_train = data_train['is_ultra']\n",
        "features_valid = data_valid.drop([\"is_ultra\"], axis=1)\n",
        "target_valid = data_valid['is_ultra']\n",
        "features_test = data_test.drop([\"is_ultra\"], axis=1)\n",
        "target_test = data_test[\"is_ultra\"]\n",
        "\n",
        "print(features_train.shape)\n",
        "print(target_train.shape)\n",
        "print(features_valid.shape)\n",
        "print(target_valid.shape)\n",
        "print(features_test.shape)\n",
        "print(target_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dL7mApyo1z3y"
      },
      "source": [
        "Seems that the dataset we are working with has a uneven number of rows, thus the awkward 1 row difference in the valid and test set."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='warning1'></a>\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "Remember to review the balance of data classes before splitting. Lets say in a extreme case you have a complete class in test size, possibly ultra class. Remember to stratify when you split between train and test, check the ```stratify``` parameter. \n",
        "\n",
        "Remember from the lesson optimal split would be 60% train, 20% validation, 20% test. Nevertheless as you only have 3000 rows, I will increase the train percentaje split and reduce validation a test set.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "You separated it as a master ! and made a shape sanity check\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TW9A-N4Z1z3y"
      },
      "source": [
        "## Investigate the quality of different models by changing hyperparameters. While Briefly describing the findings of the study."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TKPZcir61z3y"
      },
      "source": [
        "I will test various models with accuracy score. This will be done by changing hyperparameters. I will set a 0.75 threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t4WlNyi1z3y",
        "outputId": "2acf5ab9-e418-43da-feea-94d787109527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_depth = 1 : 0.7571606475716065\n",
            "max_depth = 2 : 0.7808219178082192\n",
            "max_depth = 3 : 0.7870485678704857\n",
            "max_depth = 4 : 0.7820672478206725\n",
            "max_depth = 5 : 0.7820672478206725\n"
          ]
        }
      ],
      "source": [
        "for depth in range(1, 6):\n",
        "    model1 = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
        "    model1.fit(features_train, target_train)\n",
        "    predictions_valid1 = model1.predict(features_valid)\n",
        "    print(\"max_depth =\", depth, \": \", end=\"\")\n",
        "    print(accuracy_score(target_valid, predictions_valid1))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A98A8Npw1z3y"
      },
      "source": [
        "max_depth of 3 seems to have the best quality of results being 0.787. This is good considering that it beats the 50/50 odds of guessing and also doesn't have a higher number max_depth of 5 since that could cause overfitting in the decision tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yytlyab91z3z",
        "outputId": "cc85bcf8-4620-41aa-dcd6-76cd42d416b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the best model on the validation set (n_estimators = 8): 0.7858032378580324\n"
          ]
        }
      ],
      "source": [
        "best_est=0\n",
        "best_score=0\n",
        "\n",
        "for est in range(1, 11): \n",
        "    model2 = RandomForestClassifier(random_state=12345, n_estimators=est) \n",
        "    model2.fit(features_train, target_train)\n",
        "    score2 = model2.score(features_valid, target_valid)\n",
        "    if score2 > best_score:\n",
        "        best_score = score2\n",
        "        best_est = est\n",
        "print(\"Accuracy of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_score))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LzIHgVb21z3z"
      },
      "source": [
        "N_estimators of 8 seems to have best score, but it doesn't seem to be doing better then the decision tree. With the Random Forest having a score of 0.785 and decision tree with 0.787."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r82fIIKy1z3z",
        "outputId": "7f9cdbc6-72b1-450c-98c8-27885c17e95c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the logistic regression model on the training set: 0.7423771001866832\n",
            "Accuracy of the logistic regression model on the validation set: 0.75093399750934\n"
          ]
        }
      ],
      "source": [
        "model3 = LogisticRegression(random_state=12345, solver=\"liblinear\")\n",
        "model3.fit(features_train, target_train)\n",
        "score_train = model3.score(features_train, target_train)\n",
        "score_valid = model3.score(features_valid, target_valid)\n",
        "print(\"Accuracy of the logistic regression model on the training set:\", score_train)\n",
        "print(\"Accuracy of the logistic regression model on the validation set:\", score_valid)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lh5PNOQa1z3z"
      },
      "source": [
        "Seems that the logistic regression model did the worst with an accuracy score of 0.748, not meeting the accuracy threshold of 0.75."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XNaj4iV21z30"
      },
      "source": [
        "Although not all models beat the 0.75 threshold, the best model was the decision tree model with a score of 0.787. This model will be used for the project. This makes sense, since the is_ultra column is like a bolean value with there being only 1 or 0."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='danger1'></a>\n",
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "\n",
        "1. I recommend use at least 3 hyperparameters for Decision Tree Classifier. You are already using 2 (N Estimators, max_depth), check at least one more hyper parameter: min_samples_split, min_samples_leaf, min_weight_fraction_lea, max_features, min_impurity_decrease. \n",
        "\n",
        "2. Also apply the random-forest model, the more tools you have to attack a problem the better.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='warning2'></a>\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "\n",
        "1. Also take in consideration when iterating over the hyperparameter to combine them (N Estimators x max_depth) combinations in your problems leds to 11*6 = 60 possibilities. You can after in the future iterate over this last option OPTUNA, a library dedicated to perform hyper parameter fast tuning, and used for Expert Data Scientists.\n",
        "\n",
        "2. I will Recommend you to plot the confusion matrix of train and validation sets to know if there is a unbalance classification. There maybe an improve room on this one.\n",
        "\n",
        "3. Is ok to summary all the validations results of accuracy in a summary table, better if disaggregated.\n",
        "\n",
        "4. Is sane to show accuracy on training set also.\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "Its nice you follow recomendations to use validation set to select best model and add random_state for replicability purposes\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v-jx4Q401z30"
      },
      "source": [
        "## Checking the quality of the model using the test set."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qSkBeQOI1z30"
      },
      "source": [
        "I will check the quality of the final model with the use of the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "GpwgvnpD1z30",
        "outputId": "2cb22b4f-38a6-46a2-f20c-fb6c662f000c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=12345)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(max_depth=3, random_state=12345)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_model = DecisionTreeClassifier(random_state=12345, max_depth=3)\n",
        "final_model.fit(features_train, target_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YjWaowmx1z30"
      },
      "outputs": [],
      "source": [
        "predictions = final_model.predict(features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcLgNFyy1z30",
        "outputId": "f9e50f9b-098f-4ce9-c536-aa87a250b922",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: 167\n"
          ]
        }
      ],
      "source": [
        "def error_count(answers, predictions):\n",
        "    count = 0\n",
        "    for i in range(len(answers)):\n",
        "        if answers[i] != predictions[i]:\n",
        "            count += 1\n",
        "    return count\n",
        "target_test = target_test.reset_index(drop=True)\n",
        "print('Errors:', error_count(target_test, predictions))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C_4oUWUO1z31"
      },
      "source": [
        "Target test was givving issues with the function passed and wouldn't display without resetting index. This was most likely due to the indices not aligning with the prediction list, so I reset the target_test to allign with predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXBpxzu81z31",
        "outputId": "e61a5735-920d-4a4f-e226-68e34628753c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7922885572139303\n"
          ]
        }
      ],
      "source": [
        "def accuracy(answers, predictions):\n",
        "    new = len(answers) - error_count(answers, predictions)\n",
        "    new = new/len(answers)\n",
        "    return new\n",
        "\n",
        "print('Accuracy:', accuracy(target_test, predictions))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vi244H11z32"
      },
      "source": [
        "About 8/10 this model isn't perfect, but it definitely does better then guessing(5/10) the outcome."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "You got a good model that hast more than 75% accuracy in test set ! \n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kU3KzeFY1z32"
      },
      "source": [
        "## Additional task: sanity check the model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vdcSnIc21z32"
      },
      "source": [
        "Checking how far off we are by making use of the mean squared error function in sklearn and getting the squared root of that answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Gk0PMjM1z32",
        "outputId": "00debafa-76eb-4a7a-86cb-fdba41893549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.20771144278606965\n"
          ]
        }
      ],
      "source": [
        "result = mean_squared_error(target_test, predictions)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTnAlQcB1z32",
        "outputId": "fe1ea685-38ca-43a0-a12f-1403d3d63437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.043144043464270684\n"
          ]
        }
      ],
      "source": [
        "rmse = result**2\n",
        "print(rmse)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jr-uvyQT1z32"
      },
      "source": [
        "The rmse tells us that the predictions are roughly off by 0.0431."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='warning3'></a>\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "\n",
        "1. RMSE is not a metric for clasification model. There can be three approachs for sanity check model. Since this is a bonus point complete one in cas you want to have the bonus!\n",
        "\n",
        "* Compare with constant value prediction (1 or 0).\n",
        "* Compare with random selection value prediction.\n",
        "* Plot Confusion Matrix, in order to determine you have a correct precision on each group. For the sake of the example lets say you may have a 70% good accuracy corresponding to ultra labels, and 5% corresponding to smart label, leading to 75% accuracy. But in reality you have 100% accuracy for one group and 5%/30% =16% accuray in the other grou (smart)p. Then you may a bias in the model that you should correct.\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NtYe7p-01z33"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LlFRmiqx1z33"
      },
      "source": [
        "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
        "\n",
        "I have succesfully developed a model that would assign the appropriate plan on existing user behavior. Conclusions are as followed:\n",
        "\n",
        "- There is no missing values or duplicate rows in the dataset, and all data types are correct.\n",
        "\n",
        "- I will split the data in the following order, putting 50% of the data in the training set, 25% in the validation set, and 25% in the test set. It is default to use the largest portion of data to train the model, so it can be as accurate as possible.\n",
        "\n",
        "- Although not all models beat the 0.75 threshold, the best model was the decision tree with a max_depth of 3 model, with a score of 0.787. This model will be used for the project. This makes sense, since the is_ultra column is like a bolean value with there being only 1 or 0.\n",
        "\n",
        "- The model score on the test set is about 8/10 this model isn't perfect, but it definitely does better then guessing(5/10) the outcome.\n",
        "\n",
        "- The rmse tells us that the predictions are roughly off by 0.0431."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "Good conclusion, concise and to the point.\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
        "I Enjoy your approach, the preprocessing, the clean code! The whole project is amazing, correct the tuning section with more hyperparameters and we are set. Keep going ! \n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
